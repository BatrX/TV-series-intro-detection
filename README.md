# Детекция заставок в сериалах с использованием CLIP и трансформеров

Датасеты (`train_clip_sequences` и `test_clip_sequences`) и веса моделей находятся на [Google диске](https://drive.google.com/drive/folders/1RAYoixh6BIsK_a6KoVUoTTwFe8azLG6Q?usp=drive_link). Чтобы запустить ноутбук и все ссылки работали, нужно добавить в папку с проектом папки с исходными видеоролками (разархивированные `data_test_short` и `data_train_short`) и папки из Google диска.

## Описание задачи

Цель проекта — автоматическое определение коротких **заставок (интро)** в эпизодах сериалов. Эти фрагменты, как правило, являются повторяющимися вступительными титрами или логотипами. Задача решается как **покадровая бинарная классификация**: для каждого кадра нужно определить, относится ли он к заставке (`1`) или нет (`0`).

## Основа подхода

За основу взята статья:  
[**Automatic Detection of Intro and Credits in Video using CLIP and Multihead Attention**](https://arxiv.org/abs/2504.09738)

Однако:
- В оригинальной работе определяются **и интро, и титры**, а в данной задаче — **только интро**.
- Исходный код статьи отсутствует, поэтому многие решения приходилось **интерпретировать самостоятельно** (в частности, как формировать сбалансированные последовательности, как обращаться с короткими интро и т.д.).

## Пайплайн обработки

### 1. Обработка видео

- Все видео приводятся к **1 кадру в секунду (1 FPS)**. Это соответствует статье — как **оптимальный компромисс между точностью и вычислительными затратами**.
- Используется `.json` файл с аннотациями: `start` и `end` времени заставки для каждого эпизода.

### 2. Исправление ошибок разметки

- В аннотациях часто начало заставки оказывалось **на 60 секунд позже** её конца — это было **автоматически исправлено**.
- Некоторые другие ошибки (рандомные) остались, так как их исправление требовало ручной обработки.

### 3. Формирование последовательностей

- Поскольку заставка занимает **очень малый процент** от общего видео, для сбалансированного обучения:
  - Из каждого видео берётся сегмент заставки.
  - К нему добавляется **фильм-сегмент той же длины**, следующий за заставкой.
- Все такие пары (заставка + фильм) из всех видео **объединяются в одну большую последовательность**.
- Размер итоговой последовательности:
  - Трейн: 2068 кадров
  - Тест: 992 кадра

- Эта последовательность **разбивается на отрезки по 60 кадров со страйдом 5**, чтобы:
  - Захватывать **темпоральную структуру**
  - Создать больше обучающих примеров

- Результат:
  - `train_clip_sequences`: 402 последовательности
  - `test_clip_sequences`: 189 последовательностей

### 4. Извлечение признаков (CLIP)

- Каждый кадр пропускается через **CLIP ViT-B/32**.
- Получается **512-мерный эмбеддинг** для каждого кадра.
- Итог: вход в модель имеет размер `[60, 512]` (последовательность из 60 фреймов по 512 признаков).

## Архитектура модели

```python
Input: [batch_size, 60, 512]
→ + обучаемые позиционные эмбеддинги [1, 60, 512]
→ TransformerEncoder (16 слоёв, 16 голов)
→ Linear(512 → 1) → по каждому кадру логит
```

Модель использует:

- `nn.TransformerEncoder` из PyTorch для захвата временных зависимостей между кадрами
- Обучаемые позиционные эмбеддинги
- Линейный классификатор на каждый кадр
- Функцию потерь: `BCEWithLogitsLoss` (бинарная классификация)

---

## ⚙️ Параметры обучения

| Параметр        | Значение  |
|----------------|-----------|
| Optimizer      | Adam      |
| Learning Rate  | 5e-5      |
| Batch Size     | 8         |
| Epochs         | 20, 40    |

---

## Результаты

### Accuracy

| Эпохи | Train Accuracy | Test Accuracy |
|-------|----------------|---------------|
| 20    | 0.9681         | 0.7800        |
| 40    | 0.9936         | 0.8051        |

---

### Precision / Recall / F1

#### 20 эпох

**Train:**
- Precision: `0.9750`
- Recall: `0.9606`
- F1 Score: `0.9678`

**Test:**
- Precision: `0.7802`
- Recall: `0.7753`
- F1 Score: `0.7777`

---

#### 40 эпох

**Train:**
- Precision: `0.9949`
- Recall: `0.9973`
- F1 Score: `0.9961`

**Test:**
- Precision: `0.8100`
- Recall: `0.7989`
- F1 Score: `0.8044`

> Несмотря на переобучение модели на тренировочных данных, **качество на тесте не ухудшается**, а наоборот — **незначительно растёт с увеличением числа эпох**.

